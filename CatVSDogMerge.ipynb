{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "# import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugMode = True\n",
    "testWorkflow = True\n",
    "numberData = 25000\n",
    "numberTest = 12500\n",
    "batchSize = 32\n",
    "epochs = 20\n",
    "\n",
    "filenameInceptionResNetV2 = 'featuresInceptoinResNetV2'\n",
    "filenameInceptionV3 = 'featuresInceptionV3'\n",
    "filenameResNet50 = 'featuresResNet50'\n",
    "\n",
    "# if testWorkflow:\n",
    "#     numberData = 1000\n",
    "#     numberTest = 50\n",
    "#     batchSize = 4\n",
    "#     epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(MODELTYPE, inputSize, convert2RGB, preprocessInput, fileName):\n",
    "    #read data\n",
    "    x = np.zeros((numberData, inputSize, inputSize, 3), dtype=np.uint8)\n",
    "    test = np.zeros((numberTest, inputSize, inputSize, 3), dtype=np.uint8)\n",
    "    y = np.zeros((numberData, 1), dtype=np.uint8)\n",
    "\n",
    "    for index in tqdm(range(0, numberData, 2)):\n",
    "        x[index] = cv2.resize(cv2.imread('train/cat.%d.jpg' %(index/2)), (inputSize, inputSize))\n",
    "        x[index + 1] = cv2.resize(cv2.imread('train/dog.%d.jpg' %(index/2)), (inputSize, inputSize))\n",
    "        if convert2RGB:\n",
    "            x[index]     = x[index][:,:,::-1]\n",
    "            x[index + 1] = x[index + 1][:,:,::-1]\n",
    "        y[index + 1] = 1\n",
    "    \n",
    "    for index in tqdm(range(numberTest)):\n",
    "        test[index] = cv2.resize(cv2.imread('test/%d.jpg' %(index+1)), (inputSize, inputSize))\n",
    "        if convert2RGB:\n",
    "            test[index] = test[index][:,:,::-1]\n",
    "\n",
    "    #construct model    \n",
    "    inputTensor = Input((inputSize, inputSize, 3))\n",
    "    modelInput = inputTensor\n",
    "    modelInput = Lambda(preprocessInput)(modelInput)\n",
    "    baseModel = MODELTYPE(input_tensor=modelInput, weights='imagenet', include_top=False)\n",
    "    outputFeature = GlobalAveragePooling2D()(baseModel.output)\n",
    "    model = Model(baseModel.input, outputFeature)\n",
    "    \n",
    "    #predict\n",
    "    featuresTrain = model.predict(x, verbose=debugMode)\n",
    "    featuresTest = model.predict(test, verbose=debugMode)\n",
    "    \n",
    "    #save to file\n",
    "    if os.path.exists(fileName):\n",
    "        os.remove(fileName)\n",
    "        \n",
    "    with h5py.File(fileName) as h:\n",
    "        h.create_dataset(\"train\", data=featuresTrain)\n",
    "        h.create_dataset(\"test\",  data=featuresTest)\n",
    "        h.create_dataset(\"label\", data=y)\n",
    "    \n",
    "#     #for test\n",
    "#     if testWorkflow:\n",
    "#         inputTensorTest = Input(featuresTrain.shape[1:])\n",
    "#         modelInputTest = inputTensorTest\n",
    "#         modelInputTest = Dropout(0.5)(modelInputTest)\n",
    "#         modelInputTest = Dense(1, activation='sigmoid')(modelInputTest)\n",
    "#         modelTest = Model(inputTensorTest, modelInputTest)\n",
    "\n",
    "#         modelTest.compile(optimizer='adam',\n",
    "#                       loss='binary_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "        \n",
    "#         modelTest.fit(featuresTrain, y, batch_size=batchSize, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features with ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:42<00:00, 122.00it/s]\n",
      "100%|██████████| 12500/12500 [01:04<00:00, 194.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  864/25000 [>.............................] - ETA: 1:26:30"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as piResNet50\n",
    "\n",
    "extract_feature(ResNet50, 224, False, piResNet50, filenameResNet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features with InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as piInceptionV3\n",
    "\n",
    "extract_feature(InceptionV3, 299, True, piInceptionV3, filenameInceptionV3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features with InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input as piInceptionResNetV2\n",
    "\n",
    "extract_feature(InceptionResNetV2, 299, True, piInceptionResNetV2, filenameInceptionResNetV2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict and write submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeSubmission(pred, predNumber, filename):\n",
    "    submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "    for index in tqdm(range(predNumber)):\n",
    "        submission.at[index, \"label\"] = pred[index]\n",
    "\n",
    "    submission.to_csv(filename, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "xTrainMerge = []\n",
    "xTestMerge = []\n",
    "\n",
    "index = 0\n",
    "\n",
    "for featureFilename in [filenameResNet50, filenameInceptionV3, filenameInceptionResNetV2]:\n",
    "    index += 1\n",
    "    with h5py.File(featureFilename, 'r') as h:\n",
    "        xTrain = np.array(h['train'])\n",
    "        xTrainMerge.append(xTrain)\n",
    "        \n",
    "        xTest = np.array(h['test'])\n",
    "        xTestMerge.append(xTest)\n",
    "        \n",
    "        yTrain = np.array(h['label'])\n",
    "\n",
    "    #     print (yTrain)\n",
    "        inputTensor = Input(xTrain.shape[1:])\n",
    "        modelInput = inputTensor\n",
    "        modelInput = Dropout(0.25)(modelInput)\n",
    "        modelInput = Dense(1, activation='sigmoid')(modelInput)\n",
    "        model = Model(inputTensor, modelInput)\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        model.fit(xTrain, yTrain, batch_size=batchSize, epochs=epochs, validation_split=0.2)\n",
    "        \n",
    "        pred = model.predict(xTest, verbose=True)\n",
    "        pred = pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "        writeSubmission(pred, numberTest, 'submission%d.csv' %index)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainMerge = np.concatenate(xTrainMerge, axis=1)\n",
    "xTestMerge = np.concatenate(xTestMerge, axis=1)\n",
    "\n",
    "xTrainMerge, yTrain = shuffle(xTrainMerge, yTrain)\n",
    "\n",
    "inputTensor = Input(xTrainMerge.shape[1:])\n",
    "modelInput = inputTensor\n",
    "modelInput = Dropout(0.25)(modelInput)\n",
    "modelInput = Dense(1, activation='sigmoid')(modelInput)\n",
    "model = Model(inputTensor, modelInput)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(xTrainMerge, yTrain, batch_size=batchSize, epochs=epochs, validation_split=0.2)   \n",
    "\n",
    "pred = model.predict(xTestMerge, verbose=True)\n",
    "pred = pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "writeSubmission(pred, numberTest, 'submissionMergeFeature.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission1 = pd.read_csv('submission1.csv')\n",
    "submission2 = pd.read_csv('submission2.csv')\n",
    "submission3 = pd.read_csv('submission3.csv')\n",
    "submissionMergePredict  = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "for element in list(zip(range(numberTest),submission1['label'], submission2['label'], submission3['label'])):\n",
    "    labels = element[1:]\n",
    "    submissionMergePredict.at[element[0], \"label\"] = max(labels) if min(labels) > 0.5 else (min(labels) if max(labels) < 0.5 else np.mean(labels))\n",
    "    print(submissionMergePredict.at[element[0], \"label\"], labels)\n",
    "    \n",
    "submissionMergePredict.to_csv('submissionMergePredict.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
